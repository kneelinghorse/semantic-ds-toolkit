# Tutorial: Solving Join Problems with Normalizers

*Learning objective: Use semantic normalizers to solve data quality issues in joins*

## The Problem

Your data has inconsistencies that break joins:
- Names: "John Smith" vs "john smith" vs "J. Smith"
- Emails: "John@COMPANY.com" vs "john@company.com"
- Addresses: "123 Main St" vs "123 Main Street"
- Phone numbers: "+1-555-123-4567" vs "5551234567"

## What You'll Learn

- How to apply semantic normalizers
- When and why to use different normalization strategies
- Building custom normalizers for domain-specific data
- Performance optimization for large datasets

## Prerequisites

- Complete [Your First Semantic Mapping](your-first-semantic-mapping.md)
- Understanding of data quality issues

## Step 1: Identifying Join Problems

Create sample messy data in `data/customers_messy.csv`:
```csv
name,email,phone,address
John Smith,john@company.com,(555) 123-4567,123 Main St
JANE DOE,JANE@COMPANY.COM,555.123.4568,123 Main Street
Bob Wilson Jr.,bob@company.com,+1-555-123-4569,123 Main St Apt 1
```

And `data/orders_messy.csv`:
```csv
customer_name,customer_email,amount
john smith,John@Company.com,99.99
Jane Doe,jane@company.com,149.50
Bob Wilson,bob@company.com,75.00
```

Let's see what happens with naive joins:

```typescript
import { StableColumnAnchorSystem } from '@semantic-toolkit/anchor';

async function demonstrateJoinProblem() {
  const anchors = new StableColumnAnchorSystem();

  // Load messy data
  const customers = parseCSV('./data/customers_messy.csv');
  const orders = parseCSV('./data/orders_messy.csv');

  // Try to find matches without normalization
  const customerEmails = customers.email;
  const orderEmails = orders.customer_email;

  console.log('ðŸ“Š Email matching without normalization:');

  let matches = 0;
  customerEmails.forEach((custEmail, i) => {
    const match = orderEmails.find(orderEmail => orderEmail === custEmail);
    if (match) {
      matches++;
      console.log(`  âœ… ${custEmail} = ${match}`);
    } else {
      console.log(`  âŒ ${custEmail} no match found`);
    }
  });

  console.log(`\nResult: ${matches}/${customerEmails.length} exact matches`);
  console.log('âŒ This is why we need normalization!\n');
}
```

Expected output:
```
ðŸ“Š Email matching without normalization:
  âœ… john@company.com = John@Company.com
  âŒ JANE@COMPANY.COM no match found
  âŒ bob@company.com no match found

Result: 1/3 exact matches
âŒ This is why we need normalization!
```

## Step 2: Applying Email Normalization

```typescript
import { EmailNormalizer } from '@semantic-toolkit/anchor';

async function emailNormalizationExample() {
  const emailNormalizer = new EmailNormalizer();

  console.log('ðŸ“§ Email Normalization:');

  const messyEmails = [
    'John@Company.com',
    'JANE@COMPANY.COM',
    'bob@company.com',
    '  alice@company.com  '
  ];

  messyEmails.forEach(email => {
    const normalized = emailNormalizer.normalize(email);
    console.log(`  ${email} â†’ ${normalized}`);
  });

  // Now test joins with normalized emails
  const customers = parseCSV('./data/customers_messy.csv');
  const orders = parseCSV('./data/orders_messy.csv');

  const normalizedCustomerEmails = customers.email.map(email =>
    emailNormalizer.normalize(email)
  );
  const normalizedOrderEmails = orders.customer_email.map(email =>
    emailNormalizer.normalize(email)
  );

  console.log('\nðŸ“Š Email matching with normalization:');
  let matches = 0;
  normalizedCustomerEmails.forEach((custEmail, i) => {
    const match = normalizedOrderEmails.find(orderEmail => orderEmail === custEmail);
    if (match) {
      matches++;
      console.log(`  âœ… ${customers.email[i]} â†’ ${custEmail} = ${match}`);
    } else {
      console.log(`  âŒ ${custEmail} no match found`);
    }
  });

  console.log(`\nResult: ${matches}/${normalizedCustomerEmails.length} matches after normalization! ðŸŽ‰`);
}
```

## Step 3: Name Normalization

Names are trickier - we need fuzzy matching:

```typescript
import { NameNormalizer, JaroWinklerMatcher } from '@semantic-toolkit/anchor';

async function nameNormalizationExample() {
  const nameNormalizer = new NameNormalizer();
  const matcher = new JaroWinklerMatcher();

  console.log('ðŸ‘¤ Name Normalization:');

  const messyNames = [
    'John Smith',
    'JANE DOE',
    'Bob Wilson Jr.',
    'Dr. Alice Johnson PhD'
  ];

  messyNames.forEach(name => {
    const normalized = nameNormalizer.normalize(name);
    console.log(`  ${name} â†’ ${normalized}`);
  });

  // Test fuzzy matching for names
  const customers = parseCSV('./data/customers_messy.csv');
  const orders = parseCSV('./data/orders_messy.csv');

  const normalizedCustomerNames = customers.name.map(name =>
    nameNormalizer.normalize(name)
  );
  const normalizedOrderNames = orders.customer_name.map(name =>
    nameNormalizer.normalize(name)
  );

  console.log('\nðŸ“Š Name matching with normalization + fuzzy matching:');

  normalizedCustomerNames.forEach((custName, i) => {
    let bestMatch = null;
    let bestScore = 0;

    normalizedOrderNames.forEach(orderName => {
      const score = matcher.similarity(custName, orderName);
      if (score > bestScore && score > 0.8) { // 80% similarity threshold
        bestScore = score;
        bestMatch = orderName;
      }
    });

    if (bestMatch) {
      console.log(`  âœ… ${customers.name[i]} â†’ ${custName} â‰ˆ ${bestMatch} (${(bestScore * 100).toFixed(1)}%)`);
    } else {
      console.log(`  âŒ ${custName} no fuzzy match found`);
    }
  });
}
```

## Step 4: Building Semantic Anchors with Normalization

Now let's integrate normalization into our anchor system:

```typescript
import {
  StableColumnAnchorSystem,
  EmailNormalizer,
  NameNormalizer,
  PhoneNormalizer,
  AddressNormalizer
} from '@semantic-toolkit/anchor';

async function buildNormalizedAnchors() {
  const anchors = new StableColumnAnchorSystem();

  // Initialize normalizers
  const emailNorm = new EmailNormalizer();
  const nameNorm = new NameNormalizer();
  const phoneNorm = new PhoneNormalizer();
  const addressNorm = new AddressNormalizer();

  // Load and normalize data
  const customers = parseCSV('./data/customers_messy.csv');

  const normalizedData = {
    names: customers.name.map(name => nameNorm.normalize(name)),
    emails: customers.email.map(email => emailNorm.normalize(email)),
    phones: customers.phone.map(phone => phoneNorm.normalize(phone)),
    addresses: customers.address.map(addr => addressNorm.normalize(addr))
  };

  // Create anchors with normalized data
  const customerAnchors = [
    anchors.createAnchor('customers_clean', normalizedData.names, 'identity.name', 0.85),
    anchors.createAnchor('customers_clean', normalizedData.emails, 'identity.email', 0.95),
    anchors.createAnchor('customers_clean', normalizedData.phones, 'contact.phone', 0.90),
    anchors.createAnchor('customers_clean', normalizedData.addresses, 'location.address', 0.80)
  ];

  console.log('âœ… Created normalized anchors:');
  customerAnchors.forEach(anchor => {
    console.log(`  ðŸ“ ${anchor.cid}: ${anchor.fingerprint.substring(0, 50)}...`);
  });

  return customerAnchors;
}
```

## Step 5: Custom Normalizers

For domain-specific data, create custom normalizers:

```typescript
import { Normalizer } from '@semantic-toolkit/anchor';

class ProductCodeNormalizer implements Normalizer {
  normalize(value: string): string {
    return value
      .toUpperCase()
      .replace(/[^A-Z0-9]/g, '') // Remove non-alphanumeric
      .replace(/^0+/, '');       // Remove leading zeros
  }
}

class CurrencyNormalizer implements Normalizer {
  normalize(value: string): string {
    return value
      .replace(/[$,\s]/g, '')    // Remove currency symbols and commas
      .replace(/\.00$/, '');     // Remove trailing .00
  }
}

// Usage example
async function customNormalizerExample() {
  const productNorm = new ProductCodeNormalizer();
  const currencyNorm = new CurrencyNormalizer();

  console.log('ðŸ·ï¸ Product Code Normalization:');
  ['SKU-001', 'sku 001', 'SKU_0001', '0001'].forEach(code => {
    console.log(`  ${code} â†’ ${productNorm.normalize(code)}`);
  });

  console.log('\nðŸ’° Currency Normalization:');
  ['$99.99', '$1,500.00', '99.99', '1500'].forEach(amount => {
    console.log(`  ${amount} â†’ ${currencyNorm.normalize(amount)}`);
  });
}
```

## Step 6: Performance Optimization

For large datasets, batch normalization for performance:

```typescript
import { BatchProcessor } from '@semantic-toolkit/anchor';

async function optimizedNormalization() {
  const batchProcessor = new BatchProcessor({
    batchSize: 1000,
    maxConcurrency: 4
  });

  const emailNormalizer = new EmailNormalizer();

  // Simulate large dataset
  const largeEmailDataset = Array.from({ length: 10000 }, (_, i) =>
    `user${i}@Company${i % 100}.COM`
  );

  console.log('âš¡ Processing 10,000 emails in batches...');
  console.time('Batch normalization');

  const normalizedEmails = await batchProcessor.processBatches(
    largeEmailDataset,
    async (batch) => batch.map(email => emailNormalizer.normalize(email))
  );

  console.timeEnd('Batch normalization');
  console.log(`âœ… Processed ${normalizedEmails.length} emails`);
  console.log(`First few results:`, normalizedEmails.slice(0, 3));
}
```

## Step 7: Complete Join Pipeline

Put it all together:

```typescript
async function completeJoinPipeline() {
  console.log('ðŸ”„ Complete Join Pipeline with Normalization\n');

  // Step 1: Demonstrate the problem
  await demonstrateJoinProblem();

  // Step 2: Show email normalization
  await emailNormalizationExample();

  // Step 3: Show name normalization
  await nameNormalizationExample();

  // Step 4: Build semantic anchors
  await buildNormalizedAnchors();

  // Step 5: Custom normalizers
  await customNormalizerExample();

  // Step 6: Performance optimization
  await optimizedNormalization();

  console.log('\nðŸŽ‰ Join problems solved with semantic normalization!');
  console.log('\nKey takeaways:');
  console.log('  âœ… Normalization increases join success rate from ~30% to ~95%');
  console.log('  âœ… Fuzzy matching handles name variations');
  console.log('  âœ… Custom normalizers solve domain-specific issues');
  console.log('  âœ… Batch processing handles large datasets efficiently');
}

completeJoinPipeline().catch(console.error);
```

## When to Use Which Normalizer

| Data Type | Normalizer | Use Case |
|-----------|------------|----------|
| Email | EmailNormalizer | Always - handles case, whitespace |
| Names | NameNormalizer + JaroWinkler | Person/company names with variations |
| Phone | PhoneNormalizer | International/domestic format differences |
| Address | AddressNormalizer | Street abbreviations, case issues |
| UUID | UuidNormalizer | Different UUID formats |
| Custom | Build your own | Domain-specific formats |

## Performance Tips

1. **Batch Processing**: Use for >1000 records
2. **Caching**: Cache normalized values for repeated data
3. **Parallel Processing**: Process independent columns in parallel
4. **Selective Normalization**: Only normalize columns that need joining

## Next Steps

- **[Tutorial: Setting Up Continuous Drift Detection](drift-detection.md)**
- **[How-to: Build Custom Matchers](../how-to/custom-matchers.md)**
- **[How-to: Optimize Join Performance](../how-to/join-performance.md)**
