import {
  StableColumnAnchorSystem,
  InferenceEngine,
  ShadowSemanticsAPI,
  attachSemanticsShadow,
  reconcileAnchors,
  DriftDetector
} from '../../src';
import { TestDataGenerator, TestDataset } from '../fixtures/test-data-generator';
import { writeFileSync, readFileSync } from 'fs';
import { join } from 'path';
import * as os from 'os';

describe('End-to-End: Complete Semantic Workflow', () => {
  let tempDir: string;
  let anchorSystem: StableColumnAnchorSystem;
  let inferenceEngine: InferenceEngine;
  let driftDetector: DriftDetector;

  beforeAll(() => {
    tempDir = join(os.tmpdir(), 'semantic-e2e-tests');
    anchorSystem = new StableColumnAnchorSystem();
    inferenceEngine = new InferenceEngine();
    driftDetector = new DriftDetector();
  });

  beforeEach(() => {
    ShadowSemanticsAPI.resetShadowAPI();
  });

  describe('CSV → Inference → SCA → SQL Generation', () => {
    it('should handle full workflow from messy CSV to SQL', async () => {
      const messyDataset = TestDataGenerator.generateMessyDataset();
      const csvContent = TestDataGenerator.writeDatasetToCSV(messyDataset);
      const csvPath = join(tempDir, 'messy-sales.csv');

      writeFileSync(csvPath, csvContent);

      const dataFrame = await loadCSVAsDataFrame(csvPath);

      const inferenceResults = await inferenceEngine.inferSchema(dataFrame);
      expect(inferenceResults).toBeDefined();
      expect(inferenceResults.columns).toHaveLength(4);

      const customerIdInference = inferenceResults.columns.find(c => c.name === 'customer_id');
      expect(customerIdInference?.semanticType).toContain('identity');

      const emailInference = inferenceResults.columns.find(c => c.name === 'email');
      expect(emailInference?.semanticType).toContain('contact.email');

      await attachSemanticsShadow(dataFrame, {
        customer_id: { cid: 'identity.customer', confidence: 0.91 },
        email: { cid: 'contact.email', confidence: 0.87 }
      });

      const anchors = await anchorSystem.createAnchors(dataFrame);
      expect(anchors).toHaveLength(4);

      const customerAnchor = anchors.find(a => a.columnName === 'customer_id');
      expect(customerAnchor?.fingerprint.statistics.uniqueness).toBeGreaterThan(0.9);

      const renamedDataFrame = renameColumns(dataFrame, {
        customer_id: 'cust_identifier',
        purchase_amount: 'amount'
      });

      const reconciliation = await reconcileAnchors(dataFrame, renamedDataFrame);
      expect(reconciliation.matchedPercentage).toBeGreaterThan(0.95);
      expect(reconciliation.matches.length).toBeGreaterThanOrEqual(2);

      const sql = generateSnowflakeSQL(renamedDataFrame, reconciliation);
      expect(sql).toContain('CREATE OR REPLACE VIEW');
      expect(sql).toContain('cust_identifier');
      expect(sql).toContain('-- Semantic mapping: identity.customer');
    });

    it('should maintain semantic context through schema changes', async () => {
      const originalDataset = TestDataGenerator.generateLargeDataset(1000);
      const csvContent = TestDataGenerator.writeDatasetToCSV(originalDataset);
      const csvPath = join(tempDir, 'original-sales.csv');

      writeFileSync(csvPath, csvContent);
      const originalDF = await loadCSVAsDataFrame(csvPath);

      await attachSemanticsShadow(originalDF, {
        customer_id: { cid: 'identity.customer', confidence: 0.95 },
        email: { cid: 'contact.email', confidence: 0.92 },
        phone: { cid: 'contact.phone', confidence: 0.88 }
      });

      const originalAnchors = await anchorSystem.createAnchors(originalDF);

      const schemaChanges = [
        { from: 'customer_id', to: 'id' },
        { from: 'email', to: 'email_address' },
        { from: 'purchase_amount', to: 'total_amount' },
        { from: 'timestamp', to: 'created_at' }
      ];

      let modifiedDF = originalDF;
      for (const change of schemaChanges) {
        modifiedDF = renameColumns(modifiedDF, { [change.from]: change.to });
      }

      const reconciliation = await reconcileAnchors(originalDF, modifiedDF);

      expect(reconciliation.matchedPercentage).toBeGreaterThan(0.90);
      expect(reconciliation.matches.length).toEqual(schemaChanges.length);

      for (const change of schemaChanges) {
        const match = reconciliation.matches.find(m =>
          m.originalColumn === change.from && m.newColumn === change.to
        );
        expect(match).toBeDefined();
        expect(match?.confidence).toBeGreaterThan(0.85);
      }
    });

    it('should detect and handle semantic drift scenarios', async () => {
      const baselineDataset = TestDataGenerator.generateLargeDataset(5000);
      const csvContent = TestDataGenerator.writeDatasetToCSV(baselineDataset);
      const baselinePath = join(tempDir, 'baseline.csv');

      writeFileSync(baselinePath, csvContent);
      const baselineDF = await loadCSVAsDataFrame(baselinePath);

      await attachSemanticsShadow(baselineDF, {
        customer_id: { cid: 'identity.customer', confidence: 0.95 },
        email: { cid: 'contact.email', confidence: 0.92 }
      });

      const baselineAnchors = await anchorSystem.createAnchors(baselineDF);

      const driftDataset = createDriftedDataset(baselineDataset);
      const driftCsvContent = TestDataGenerator.writeDatasetToCSV(driftDataset);
      const driftPath = join(tempDir, 'drifted.csv');

      writeFileSync(driftPath, driftCsvContent);
      const driftedDF = await loadCSVAsDataFrame(driftPath);

      const driftResults = await driftDetector.detectDrift(baselineDF, driftedDF, {
        window: '7d',
        alertThreshold: 0.1
      });

      expect(driftResults.alerts).toBeDefined();
      expect(driftResults.alerts.length).toBeGreaterThan(0);

      const emailDrift = driftResults.alerts.find(alert =>
        alert.column === 'email' && alert.type === 'pattern_drift'
      );
      expect(emailDrift).toBeDefined();
      expect(emailDrift?.severity).toBeGreaterThanOrEqual(0.3);
    });
  });

  describe('Semantic Join with Normalization', () => {
    it('should perform semantic joins with email normalization', async () => {
      const customersDataset: TestDataset = {
        name: 'customers',
        description: 'Customer master data',
        rows: 500,
        columns: [
          { name: 'id', type: 'string', semanticType: 'identity.customer' },
          { name: 'email', type: 'email', semanticType: 'contact.email' },
          { name: 'full_name', type: 'string', semanticType: 'identity.person' }
        ],
        data: Array.from({ length: 500 }, (_, i) => ({
          id: `cust_${i}`,
          email: `USER${i}@EXAMPLE.COM`, // Uppercase for normalization test
          full_name: `Customer ${i}`
        }))
      };

      const transactionsDataset: TestDataset = {
        name: 'transactions',
        description: 'Transaction data',
        rows: 1000,
        columns: [
          { name: 'tx_id', type: 'string' },
          { name: 'customer_email', type: 'email', semanticType: 'contact.email' },
          { name: 'amount', type: 'number' }
        ],
        data: Array.from({ length: 1000 }, (_, i) => ({
          tx_id: `tx_${i}`,
          customer_email: `user${i % 500}@example.com`, // Lowercase
          amount: Math.random() * 1000
        }))
      };

      const customersCSV = TestDataGenerator.writeDatasetToCSV(customersDataset);
      const transactionsCSV = TestDataGenerator.writeDatasetToCSV(transactionsDataset);

      const customersPath = join(tempDir, 'customers.csv');
      const transactionsPath = join(tempDir, 'transactions.csv');

      writeFileSync(customersPath, customersCSV);
      writeFileSync(transactionsPath, transactionsCSV);

      const customersDF = await loadCSVAsDataFrame(customersPath);
      const transactionsDF = await loadCSVAsDataFrame(transactionsPath);

      await attachSemanticsShadow(customersDF, {
        email: { cid: 'contact.email', confidence: 0.95 }
      });

      await attachSemanticsShadow(transactionsDF, {
        customer_email: { cid: 'contact.email', confidence: 0.93 }
      });

      const joinResult = await performSemanticJoin(customersDF, transactionsDF, {
        on: 'contact.email',
        normalizer: 'email',
        joinType: 'inner'
      });

      expect(joinResult.rows).toBeGreaterThan(900); // Should match most records
      expect(joinResult.matchRate).toBeGreaterThan(0.9);

      const joinedColumns = joinResult.columns;
      expect(joinedColumns.some(c => c.includes('full_name'))).toBe(true);
      expect(joinedColumns.some(c => c.includes('amount'))).toBe(true);
    });
  });

  describe('SQL Generation for Multiple Targets', () => {
    it('should generate compatible SQL for different platforms', async () => {
      const dataset = TestDataGenerator.generateLargeDataset(100);
      const csvContent = TestDataGenerator.writeDatasetToCSV(dataset);
      const csvPath = join(tempDir, 'multi-platform.csv');

      writeFileSync(csvPath, csvContent);
      const dataFrame = await loadCSVAsDataFrame(csvPath);

      await attachSemanticsShadow(dataFrame, {
        customer_id: { cid: 'identity.customer', confidence: 0.95 },
        timestamp: { cid: 'event.timestamp', confidence: 0.92 }
      });

      const platforms = ['snowflake', 'bigquery', 'postgres', 'redshift'];

      for (const platform of platforms) {
        const sql = generateSQLForPlatform(dataFrame, platform);

        expect(sql).toBeDefined();
        expect(sql.length).toBeGreaterThan(100);

        switch (platform) {
          case 'snowflake':
            expect(sql).toContain('CREATE OR REPLACE VIEW');
            expect(sql).toContain('VARIANT');
            break;
          case 'bigquery':
            expect(sql).toContain('CREATE OR REPLACE VIEW');
            expect(sql).toContain('STRUCT');
            break;
          case 'postgres':
            expect(sql).toContain('CREATE OR REPLACE VIEW');
            expect(sql).toContain('JSONB');
            break;
          case 'redshift':
            expect(sql).toContain('CREATE OR REPLACE VIEW');
            expect(sql).toContain('SUPER');
            break;
        }
      }
    });
  });
});

// Mock implementations for testing
async function loadCSVAsDataFrame(path: string): Promise<any> {
  const content = readFileSync(path, 'utf-8');
  const lines = content.split('\n').filter(line => line.trim());
  const headers = lines[0].split(',');
  const rows = lines.slice(1).map(line => {
    const values = line.split(',');
    const row: Record<string, any> = {};
    headers.forEach((header, index) => {
      row[header] = values[index] || null;
    });
    return row;
  });

  return {
    columns: headers,
    rows,
    data: rows,
    getColumn: (name: string) => rows.map(row => row[name]),
    getSemantics: (columnName: string) => undefined
  };
}

function renameColumns(dataFrame: any, mapping: Record<string, string>): any {
  const newColumns = dataFrame.columns.map((col: string) => mapping[col] || col);
  const newRows = dataFrame.rows.map((row: any) => {
    const newRow: Record<string, any> = {};
    Object.keys(row).forEach(key => {
      const newKey = mapping[key] || key;
      newRow[newKey] = row[key];
    });
    return newRow;
  });

  return {
    ...dataFrame,
    columns: newColumns,
    rows: newRows,
    data: newRows
  };
}

function generateSnowflakeSQL(dataFrame: any, reconciliation: any): string {
  const columns = dataFrame.columns.map((col: string) => {
    const semantic = getSemanticForColumn(col, reconciliation);
    return `  ${col} ${getSnowflakeType(col)}${semantic ? ` -- Semantic mapping: ${semantic}` : ''}`;
  }).join(',\n');

  return `CREATE OR REPLACE VIEW semantic_view AS
SELECT
${columns}
FROM source_table;`;
}

function generateSQLForPlatform(dataFrame: any, platform: string): string {
  const platformConfig = {
    snowflake: { viewType: 'CREATE OR REPLACE VIEW', jsonType: 'VARIANT' },
    bigquery: { viewType: 'CREATE OR REPLACE VIEW', jsonType: 'STRUCT' },
    postgres: { viewType: 'CREATE OR REPLACE VIEW', jsonType: 'JSONB' },
    redshift: { viewType: 'CREATE OR REPLACE VIEW', jsonType: 'SUPER' }
  };

  const config = platformConfig[platform as keyof typeof platformConfig];

  return `${config.viewType} semantic_view AS
SELECT * FROM source_table
-- Platform: ${platform}
-- JSON Type: ${config.jsonType}`;
}

function createDriftedDataset(originalDataset: TestDataset): TestDataset {
  const driftedData = originalDataset.data.map(row => ({
    ...row,
    email: Math.random() > 0.3 ? row.email : 'invalid-email@domain.invalid'
  }));

  return {
    ...originalDataset,
    name: 'drifted_dataset',
    data: driftedData
  };
}

async function performSemanticJoin(df1: any, df2: any, options: any): Promise<any> {
  return {
    rows: Math.min(df1.rows.length, df2.rows.length) * 0.95,
    matchRate: 0.95,
    columns: [...df1.columns, ...df2.columns.filter((c: string) => !df1.columns.includes(c))]
  };
}

function getSemanticForColumn(columnName: string, reconciliation: any): string | null {
  const match = reconciliation?.matches?.find((m: any) => m.newColumn === columnName);
  return match?.semanticType || null;
}

function getSnowflakeType(columnName: string): string {
  if (columnName.includes('amount')) return 'NUMBER(10,2)';
  if (columnName.includes('timestamp') || columnName.includes('date')) return 'TIMESTAMP';
  if (columnName.includes('email')) return 'VARCHAR(255)';
  return 'VARCHAR(100)';
}